\فصل{ادبیات پژوهش و کارهای پیشین}



\قسمت{مقدمه}

مرور ادبیات مطالعات پیشرفته مرتبط با روش پیشنهادی در این بخش ارائه شده است. این بخش شامل مباحثی پیرامون تقطیر دانش، مکانیزم توجه و مدل طیفی عمیق است.

\قسمت{تقطیر دانش}

تقطیر دانش Distillation) (Knowledge رویکردی نوین در حوزه یادگیری عمیق است که نخستین‌بار توسط هینتون و همکاران \cite{hinton2015distillingknowledgeneuralnetwork} معرفی شد. ایده اصلی در این روش آن است که یک مدل معلم (Teacher) بزرگ و توانمند، توزیع خروجی خود را با مدل دانش‌آموز (Student) کوچک‌تری به اشتراک بگذارد. در این فرایند، به‌جای استفاده صرف از برچسب‌های سخت Labels) (Hard از نگاشت‌های احتمالاتی و اطلاعات غنی‌تر مدل معلم برای راهنمایی دانش‌آموز استفاده می‌شود. بدین ترتیب، تابع هدف تقطیر دانش غالباً بر پایه حداقل‌سازی واگرایی  (KL-Divergence) میان توزیع خروجی‌های معلم و دانش‌آموز است. این رویکرد امکان فشرده‌سازی و سبک‌سازی مدل‌ها را فراهم می‌کند و در نتیجه، پیاده‌سازی شبکه‌های عمیق در دستگاه‌های با منابع محاسباتی محدود نظیر تلفن‌های همراه را تسهیل می‌سازد.

پس از معرفی ایده اولیه توسط هینتون و همکاران، شیوه‌های گوناگونی برای بهبود فرایند تقطیر دانش ارائه شده است. مثلاً در FitNet \cite{romero2015fitnetshintsdeepnets}، از نگاشت ویژگی‌های لایه‌های میانی مدل معلم برای آموزش مدل دانش‌آموز بهره گرفته می‌شود تا دانش‌آموز بتواند نمایش‌های درونی عمیق‌تری را بیاموزد. در رویکرد دیگر، زاگوریو و کوموداکیس \cite{zagoruyko2017wideresidualnetworks}، نقشه توجه Attention) (Map مربوط به لایه‌های میانی معلم استخراج و به دانش‌آموز منتقل می‌شود. همچنین در RKD \cite{park2019relationalknowledgedistillation}، فاصله و زاویه میان بردارهای ویژگی به‌منظور حفظ همبستگی نمونه‌ها در فضای ویژگی استخراج می‌شود. در پژوهش دیگری \cite{peng2019correlationcongruenceknowledgedistillation}، سازوکاری برای موازنه میان سازگاری نمونه‌ها و همبستگی میان آن‌ها پیشنهاد شده است.

از سوی دیگر، برخی کارها تلاش کرده‌اند با به‌کارگیری ورودی‌های ترکیبی (Mixup) یک توزیع نرم‌تر از نمونه‌ها ایجاد کنند تا آموزش دانش‌آموز تسهیل شود \cite{zhao2021similaritytransferknowledgedistillation}. همچنین در شماری از پژوهش‌ها، ترفندهای مختلفی برای ارتقای فرایند تقطیر دانش ارایه شده است؛ برای مثال می‌توان به استفاده از تابع زیان تطبیقی آنتروپی متقاطع \cite{s20164616}، کاهش دوره زمانی اعمال تقطیر \cite{mansourian2023aicsdadaptiveinterclasssimilarity}، هرس ویژگی‌ها پیش از اعمال تقطیر \cite{park2022prunemodeldistill} و بررسی نقش دمای (Temperature) خروجی و پروژه‌کننده‌ها (Projectors) در انتقال دانش \cite{miles2024understandingroleprojectorknowledge} اشاره کرد.

تقطیر دانش مزیت‌های چشمگیری دارد؛ از جمله کاهش اندازه مدل بدون افت چشمگیر در دقت، که این موضوع برای بسیاری از کاربردهای عملی هوش مصنوعی حیاتی است. به‌کارگیری مدل‌های کوچک‌تر در هوش مصنوعی مستلزم زمان پاسخ‌دهی سریع‌تر و مصرف انرژی کمتر است. بااین‌حال، چالش‌هایی نیز وجود دارد؛ از جمله انتخاب مناسب لایه‌ها برای تقطیر، تنظیم ضرایب دما برای کنترل نرمی توزیع خروجی معلم، و تدارک سازوکاری برای حفظ همبستگی نمونه‌ها در فضای ویژگی.

در مجموع، تقطیر دانش یکی از کلیدی‌ترین تکنیک‌های فشرده‌سازی و بهبود بهره‌وری مدل‌های یادگیری عمیق محسوب می‌شود. مطالعات متعددی که در این حوزه صورت گرفته‌اند، نشان می‌دهند با طراحی خلاقانه زیان‌ها، توجه به لایه‌های درونی، و بهره‌گیری از راهکارهای بهینه‌سازی، می‌توان از توانایی مدل‌های معلم برای ساخت مدل‌های دانش‌آموز کوچک‌تر و در عین حال توانمند بهره برد. این پیشرفت‌ها مسیر را برای گسترش استفاده از شبکه‌های عمیق در کاربردهای دنیای واقعی و محیط‌های محدودتر از نظر محاسباتی هموارتر ساخته است.

\قسمت{تقطیر دانش برای بخش‌بندی معنایی}


تقطیر دانش برای ایجاد شبکه‌های سریع و فشردهٔ بخش‌بندی معنایی مورد استفاده قرار گرفته است \cite{heo2019comprehensiveoverhaulfeaturedistillation} \cite{yang2022crossimagerelationalknowledgedistillation}. روش SKDS \cite{Liu_2019_CVPR}، تقطیر دانش را در سطح پیکسل به‌کار گرفت. اگرچه این رویکرد در وظایف دیگر موفق ظاهر شده است، اما در بهبود عملکرد بخش‌بندی معنایی با محدودیت‌هایی مواجه است. تمرکز بر روابط پیکسلیِ منفرد در این روش‌ها، مانع از دریافت بافتار ساختاری مورد نیاز در پیش‌بینی چگال می‌شود. با در نظر گرفتن این محدودیت‌ها، SKDS همچنین نشان داده است که ترکیب راهبردهای مکمل (یعنی تقطیر دانش جفتی و کلی‌نگر در کنار تقطیر دانش پیکسلی) می‌تواند با در نظر گرفتن وابستگی روابط بین پیکسل‌ها، در بهبود عملکرد بخش‌بندی معنایی مؤثر باشد. تقطیر دانش کلی‌نگر، روابط مرتبهٔ بالاتر بین نقشه‌های بخش‌بندی‌ای که از مدل معلم تقطیر شده‌اند را با شبکهٔ دانش‌آموز همتراز می‌کند.

این پژوهش عمدتاً بر تقطیر دانش جفتی تمرکز دارد. بر اساس چارچوب میدان تصادفی مارکفِ دوتایی، SKDS پیشنهاد می‌کند تا شباهت‌های جفتی میان پیکسل‌ها در نظر گرفته شود تا یکنواختی در برچسب‌گذاری فضایی بهبود یابد. همچنین، Xie و همکاران \cite{xie2018improvingfastsegmentationteacherstudent} از رویکردی مبتنی بر نقشهٔ ویژگی در سطح پیکسل با تقطیر جفتی استفاده کرده‌اند که اختلاف احتمالات محلیِ هر پیکسل با هشت همسایه‌اش را لحاظ می‌کند. با الهام از این رویکرد، مطالعات بعدی متعددی بهبودهای قابل‌توجهی به دست آورده‌اند. به عنوان نمونه، Feng و همکاران \cite{Feng_2021} روابط جفتی در سطح کلاس را از طریق شباهت در ابعاد طبقه‌ها تقطیر می‌کنند. Liu و همکاران \cite{liu2022exploringinterchannelcorrelationdiversitypreserved} شباهت‌ها و تغییرات در کانال‌های مختلف یک نقشهٔ ویژگی را استخراج می‌کنند. Yim و همکاران \cite{8100237} جریان بین لایه‌های شبکه را با محاسبهٔ ضرب داخلی بین نقشه‌های ویژگی سطوح متوالی تعریف می‌کنند. Tung و همکاران \cite{tung2019similaritypreservingknowledgedistillation} نیز تقطیر جفتی در سطح نمونه را در نظر گرفته‌اند؛ بدین صورت که با محاسبهٔ (نا)شباهت بین نمونه‌های موجود در یک دسته (batch)، شبکهٔ دانش‌آموز را تمرین می‌دهند تا این روابط را در فضای نمایش خودش حفظ کند. تقطیر جفتی در سطح کانال در \cite{s20164616} و \cite{liu2022exploringinterchannelcorrelationdiversitypreserved} بررسی شده است. در این راستا، Park و همکاران \cite{s20164616} تابع زیان همبستگی کانال و فضایی (CSC) را ارائه کرده‌اند تا بتوان کل رابطهٔ بلندبرد در نقشهٔ ویژگی را استخراج و منتقل کرد. جدول I خلاصه‌ای از زیان‌های جفتی را که در روش‌های مذکور برای تقطیر دانش استفاده شده‌اند، نشان می‌دهد.

در این مطالعه، روشی برای تقطیر جفتی پیشنهاد می‌شود که مشابه کار \cite{liu2022exploringinterchannelcorrelationdiversitypreserved} است. در این روش، ابتدا توزیع‌های درون‌رده‌ای (intra-class) برای هر کلاس محاسبه شده و سپس با محاسبهٔ یک ماتریس شباهت بین‌رده‌ای (inter-class)، برای تقطیر استفاده می‌شود. افزون بر این، با الهام از \cite{zhou2020channeldistillationchannelwiseattention}، یک راهبرد آموزشی تطبیقی برای شبکهٔ دانش‌آموز با استفاده از زیان تقطیر مورد بررسی قرار گرفته است.


\قسمت{روش‌های طیفی}


نظریه طیفی گراف‌ها از مطالعه عملگرهای پیوسته روی خمینه‌های ریمانی \cite{Cheeger} نشأت گرفته است. در ادامه، پژوهش‌های بعدی این خط تحقیقاتی به فضای گسسته گراف‌ها منتقل شدند و نتایج متعددی نشان دادند که ویژگی‌های کلی گراف‌ها با مقادیر ویژه و بردارهای ویژه ماتریس لاپلاسین آن‌ها ارتباط نزدیکی دارند. دو مورد از این نتایج برای درک کار ما ضروری هستند:

نخست، \cite{Fiedler1973} نشان داده است که دومین مقدار ویژه کوچک یک گراف - که اکنون به آن اتصال جبری یا مقدار ویژه فیدلر می‌گویند - میزان اتصال گراف را کمّی‌سازی می‌کند. در این پژوهش، از بردار ویژه فیدلر برای مکان‌یابی اشیاء استفاده شده است. دوم، \cite{Donath1973LowerBF} و \cite{Fiedler1973} نشان داده‌اند که بردارهای ویژه ماتریس لاپلاسین گراف‌ها منجر به بخش‌بندی‌هایی از گراف با کمترین انرژی می‌شوند. در این پژوهش، از این ایده برای استخراج بخش‌بندی‌های معنایی از ماتریس هم‌آیندی معنایی تک‌هنگاری (patch-wise) استفاده شده است.


جالب توجه است که مقدار ویژه فیدلر نه تنها در تحلیل شبکه‌ها، بلکه در کاربردهای عملی نظیر بهینه‌سازی حمل‌ونقل و تحلیل شبکه‌های اجتماعی نیز مورد استفاده قرار می‌گیرد. همچنین، بخش‌بندی مبتنی بر انرژی کمینه در حال حاضر کاربرد گسترده‌ای در سیستم‌های توصیه‌گر و خوشه‌بندی داده‌های بزرگ مقیاس یافته است.

روش‌های طیفی گراف توسط \cite{NIPS2001_801272ee} و \cite{868688} در جوامع یادگیری ماشین و بینایی کامپیوتر محبوبیت فراوانی پیدا کردند. Shi و همکاران \cite{868688} مسئله بخش‌بندی تصویر را در قالب برش‌های گراف فرموله کردند؛ یعنی یافتن بخش‌بندی‌ای از گراف (تصویر) که شباهت بین بخش‌ها را کمینه کند. آن‌ها خاطرنشان کردند که یافتن برش کمینه معمولاً به بخش‌بندی‌هایی کوچک‌تر از حد مطلوب منجر می‌شود. به همین دلیل، این روش را با نرمال‌سازی بر اساس وزن کل یال‌های متصل به هر بخش تعدیل کردند. Ng و همکاران \cite{NIPS2001_801272ee} نیز تجزیه طیفی را انجام دادند و سپس بردارهای ویژه را در امتداد بعد ویژه روی هم قرار داده و خوشه‌بندی کردند تا تعداد ثابتی از بخش‌ها حاصل شود.


روش خوشه‌بندی مبتنی بر بردارهای ویژه امروزه کاربردهای گسترده‌ای در تحلیل تصاویر پزشکی و سامانه‌های تشخیص خودکار اشیا، به‌ویژه در پردازش تصاویر ماهواره‌ای، یافته است. همچنین، نرمال‌سازی پیشنهادی Shi و همکاران مبنایی برای توسعه معیارهای پیشرفته شباهت در شبکه‌های عصبی عمیق شده است.

\قسمت{مکانیسم توجه Mechanism) (Attention}


این مکانیسم به مدل‌ها امکان می‌دهد تا اطلاعات زمینه‌ای محلی را از تصاویر با دقت بالاتری استخراج کنند \cite{vaswani2023attentionneed}. روش‌های مختلفی برای محاسبه توجه وجود دارد که هر کدام بر سطوح متفاوتی تمرکز می‌کنند. برای مثال، SE-NET \cite{8578843} با استفاده از بلوک‌های "فشرده‌سازی-تحریک" (Squeeze-and-Excitation)، توجه را در سطح بین‌کانالی محاسبه می‌کند و با تنظیم وزن کانال‌ها، ویژگی‌های مرتبط را تقویت می‌نماید. از سوی دیگر، SGE-NET \cite{li2019spatialgroupwiseenhanceimproving} با تقسیم ویژگی‌ها به زیرگروه‌های فضایی و محاسبه توجه جداگانه برای هر گروه، به بهبود تشخیص جزئیات ظریف کمک می‌کند. در مقابل، توجه خودیاری (Self-attention) \cite{Self_Attention} با محاسبه شباهت زوجی پیکسل‌های ورودی، ارتباطات بلندمدت در فضای تصویر را مدل‌سازی می‌کند.

روش‌های ترکیبی مانند BAM \cite{park2018bambottleneckattentionmodule} با ادغام توجه کانالی و فضایی به‌صورت موازی، و CBAM \cite{woo2018cbamconvolutionalblockattention} با اجرای متوالی توجه کانالی و سپس توجه فضایی، رویکردهای جامع‌تری ارائه می‌دهند. در CBAM، ابتدا با استفاده از توجه کانالی، اهمیت هر کانال ویژگی مشخص می‌شود و سپس توجه فضایی، نواحی کلیدی تصویر را شناسایی می‌کند. این تعامل پویا بین کانال و فضا، مکانیسم CBAM را به یک ابزار قدرتمند برای بهبود بازنمایی ویژگی‌ها تبدیل کرده است.

در سال‌های اخیر، روش‌های مقیاس‌پذیرتری مانند EMA \cite{Ouyang_2023} معرفی شده‌اند که با گروه‌بندی کانال‌ها و اعمال توجه چندمقیاسی، کارایی محاسباتی را افزایش می‌دهند. در حوزه تقطیر دانش، پژوهش‌هایی مانند \cite{9678134} با الهام از مفاهیم مطرح‌شده در \cite{8953974}، از توجه فضایی خودیاری برای بهبود فرآیند تقطیر استفاده کرده‌اند. این روش‌ها با تمرکز بر انتقال اطلاعات ساختاری از مدل پیچیده (معلم) به مدل ساده‌تر (دانش‌آموز)، عملکرد مدل‌های سبک‌وزن را ارتقا می‌دهند.

در این پژوهش، از مکانیسم CBAM برای پالایش ویژگی‌های خام استفاده شده است، چرا که این مکانیسم به‌صورت تطبیقی، هم توجه فضایی و هم توجه کانالی را اعمال می‌کند و تعادل مناسبی بین پیچیدگی محاسباتی و دقت ایجاد می‌نماید. تا آنجا که می‌دانیم، این اولین باری است که از ترکیب توجه کانالی و فضایی در فرآیند تقطیر دانش استفاده می‌شود. این نوآوری امکان استخراج همزمان الگوهای کلی (از طریق توجه کانالی) و جزئیات موضعی (از طریق توجه فضایی) را فراهم می‌کند و انتقال دانش را بین مدل‌ها کارآمدتر می‌سازد.

\قسمت{جمع‌بندی}

در این بخش، به توضیحات و اصطلاحاتی در زمینه های بخش‌بندی تصاویر، تقطیر دانش، مدل های طیفی و مکانیسم توجه پرداختیم. در هر قسمت توضیحاتی درباره مدل های موجود و کارهای گذشته آورده‌ایم که در ادامه کار به خواندن بهتر و فهم راحت تر خواننده کمک شایانی می‌کند.

\newpage